# MCP Server Environment Configuration
# Valid boolean values: true, false (case-insensitive)

#───────────────────────────────────────────────
# Node.js Environment Mode
#───────────────────────────────────────────────
NODE_ENV=production
# PORT=3000

#───────────────────────────────────────────────
# CORS Configuration
#───────────────────────────────────────────────
ENABLE_CORS=false
CORS_ORIGIN="*"

#───────────────────────────────────────────────
# Proxy Configuration
#───────────────────────────────────────────────
ENABLE_PROXY=false
# SOCKS5_PROXY=
# HTTPS_PROXY=
# HTTP_PROXY=

#───────────────────────────────────────────────
# SSL/TLS Configuration
#───────────────────────────────────────────────
# NODE_TLS_REJECT_UNAUTHORIZED=1
# NODE_USE_SYSTEM_CA=0

#───────────────────────────────────────────────
# Debug Configuration
#───────────────────────────────────────────────
DRY_RUN=false
WRITE_DEBUG_TERMINAL=false
WRITE_DEBUG_FILE=false
# MCP_LOG_PATH=./mcp-debug.log

#───────────────────────────────────────────────
# Certificate Configuration
#───────────────────────────────────────────────
# This variable is used for pointing to a directory with one or more .crt files.
# It will be used to update the trust store with the certificates found in this directory
CERT_HOST_FOR_STORE=./certs/store

#───────────────────────────────────────────────
# Search Engine Configuration
#───────────────────────────────────────────────
# Valid values: bing, duckduckgo, brave
DEFAULT_SEARCH_ENGINES=bing,duckduckgo,brave

#───────────────────────────────────────────────
# LLM Sampling Configuration
#───────────────────────────────────────────────
# When SAMPLING=true, search results are filtered by an LLM for relevance.
# Requires: LLM_BASE_URL (required) + LLM_NAME (required) + LLM_API_KEY (optional for local models)
#
# Strategy:
#   - By default, IDE sampling is preferred if available (via MCP Protocol)
#   - Set SKIP_IDE_SAMPLING=true to always use the external API instead
#   - If IDE is not available, external API is used as fallback
#
# Examples:
#   OpenRouter:    LLM_BASE_URL="https://openrouter.ai/api/v1" LLM_API_KEY="sk-..." LLM_NAME="google/gemini-2.0-flash-001"
#   Local Ollama:  LLM_BASE_URL="http://localhost:11434/v1" LLM_NAME="llama3.2"
#   LM Studio:     LLM_BASE_URL="http://localhost:1234/v1" LLM_NAME="local-model"
#
SAMPLING=false
# SKIP_IDE_SAMPLING=false
# LLM_BASE_URL=
# LLM_API_KEY=
# LLM_NAME=
# LLM_TIMEOUT_MS=30000

#───────────────────────────────────────────────
# Deep Search Configuration
#───────────────────────────────────────────────
DEEP_SEARCH_ENABLED=true
# DEEP_SEARCH_MAX_LOOPS=3
# DEEP_SEARCH_RESULTS_PER_ENGINE=3
# DEEP_SEARCH_SATURATION_THRESHOLD=0.6
# DEEP_SEARCH_MAX_CITATION_URLS=10  # -1 = no limit
# SKIP_COOLDOWN=false

#───────────────────────────────────────────────
# Docker Configuration
#───────────────────────────────────────────────
# DOCKER_ENVIRONMENT=false
# CHROMIUM_EXECUTABLE_PATH=